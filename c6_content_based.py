# -*- coding: utf-8 -*-
"""c6:content_based.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iloNzajD_BhbGFQ5iws3boVKvLDJxvZ0
"""

! cat /root/.kaggle/kaggle.json
! mkdir /root/.kaggle

! echo '{"username":"your-kaggle-username-here","key":"your-kaggle-key-here"}' > /root/.kaggle/kaggle.json

! kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews
! unzip imdb-dataset-of-50k-movie-reviews.zip

import pandas as pd

imdb_df = pd.read_csv("IMDB Dataset.csv")
imdb_df.head()

imdb_df.review = imdb_df.review.str.replace('<.+/>', ' ', regex=True)
imdb_df.review.head()



import nltk
nltk.download('punkt')

from nltk.tokenize import sent_tokenize

imdb_sentence_based_review = imdb_df.review.apply(sent_tokenize)

imdb_sentence_based_review.head()

from nltk.tokenize import TreebankWordTokenizer

tbwt = TreebankWordTokenizer()

imdb_treebank_based_review = imdb_df.review.apply(tbwt.tokenize)

imdb_treebank_based_review.head()

from nltk.tokenize import RegexpTokenizer

ret = RegexpTokenizer('[a-zA-Z0-9\'\.]+')

imdb_regex_based_review = imdb_df.review.apply(ret.tokenize)

nltk.download('stopwords')

from nltk.corpus import stopwords

sw = set(stopwords.words('english'))

def sw_removal(tokens):
  clean_tokens = [t for t in tokens if t not in sw]
  return clean_tokens

imdb_sw_treebank_based_review = imdb_treebank_based_review.apply(sw_removal)

imdb_sw_treebank_based_review.head()

! pip install langdetect

from langdetect import detect

print(detect('This is English'))

from nltk.stem.snowball import SnowballStemmer

ess = SnowballStemmer('english', ignore_stopwords=True)

print(ess.stem('flies'))

fss = SnowballStemmer('french', ignore_stopwords=True)
print(fss.stem('courais'))

from nltk.stem.snowball import PorterStemmer
from nltk.stem.lancaster import LancasterStemmer

print(ess.stem('teeth'))

ps = PorterStemmer()
print(ps.stem('teeth'))

ls = LancasterStemmer()
print(ls.stem('teeth'))

print(ps.stem('teen'))
print(ps.stem('teenager'))

print(ls.stem('teen'))
print(ls.stem('teenager'))

from sklearn.feature_extraction.text import CountVectorizer

cv = CountVectorizer()
vectorized_corpus = cv.fit_transform(imdb_df.review)
print(vectorized_corpus.todense())

print(cv.vocabulary_)

def tokenizer(sentence):
  tokens = ret.tokenize(sentence)
  return [ess.stem(t) for t in tokens if t not in sw]



from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

le = LabelEncoder()
sentiment = le.fit_transform(imdb_df.sentiment)

tfidfv = TfidfVectorizer(stop_words='english',
                         tokenizer=tbwt.tokenize,
                         max_features=10000)
review = tfidfv.fit_transform(imdb_df.review)

review.shape, sentiment.shape

X_train, X_test, Y_train, Y_test = train_test_split(review,
                                                    sentiment,
                                                    test_size=0.2)

X_train.shape, X_test.shape

X_train

from sklearn.naive_bayes import BernoulliNB

bnb = BernoulliNB()
bnb.fit(X_train.todense(), Y_train)
score = bnb.score(X_test.todense(), Y_test)
print('Score: %.3f' % score)

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()
dt.fit(X_train.todense(), Y_train)
score = dt.score(X_test.todense(), Y_test)
print('Score: %.3f' % score)

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()
rf.fit(X_train.todense(), Y_train)
score = rf.score(X_test.todense(), Y_test)
print('Score: %.3f' % score)

fi = rf.feature_importances_

fi

fi.max(), fi.min()



"""# MovieLens Data"""

! wget http://files.grouplens.org/datasets/movielens/ml-1m.zip
! unzip ml-1m.zip

import pandas as pd
import numpy as np

movies_df = pd.read_csv('ml-1m/movies.dat', sep='::', names=['MovieID', 'Title', 'Genres'], engine='python')
movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)

movies_df.shape

movies_df.head()

movies_df.Genres = movies_df.Genres.str.replace("|", " ")
movies_df.Genres.head()

from sklearn.feature_extraction.text import TfidfVectorizer
tfidfv = TfidfVectorizer()
vectorized_corpus = tfidfv.fit_transform(movies_df.Genres)
print(vectorized_corpus.todense())

from sklearn.neighbors import NearestNeighbors

model_knn = NearestNeighbors(metric='cosine',
                             algorithm='brute',
                             n_neighbors=20, n_jobs=-1)

model_knn.fit(vectorized_corpus)

model_knn.kneighbors(vectorized_corpus.todense()[1], 4,
                     return_distance=True)

print(movies_df.iloc[1])
print(movies_df.iloc[124])

