# -*- coding: utf-8 -*-
"""c12:evaluating_techniques.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lQnCeASkUqkz--azeLWuOYtcyYnKBRcn
"""

! cat /root/.kaggle/kaggle.json
! mkdir /root/.kaggle

! echo '{"username":"your-kaggle-username-here","key":"your-kaggle-key-here"}' > /root/.kaggle/kaggle.json

! kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews
! unzip imdb-dataset-of-50k-movie-reviews.zip

import pandas as pd

imdb_df = pd.read_csv("IMDB Dataset.csv")
imdb_df.head()

imdb_df.review = imdb_df.review.str.replace('<.+/>', ' ', regex=True)
imdb_df.review.head()



import nltk
nltk.download('punkt')

from nltk.tokenize import TreebankWordTokenizer

tbwt = TreebankWordTokenizer()

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder

from sklearn.model_selection import train_test_split

le = LabelEncoder()
sentiment = le.fit_transform(imdb_df.sentiment)
sentiment

sentiment.shape

tfidfv = TfidfVectorizer(stop_words='english',
                         tokenizer=tbwt.tokenize,
                         max_features=10000)
review = tfidfv.fit_transform(imdb_df.review)

review

review.shape

X_train, X_test, Y_train, Y_test = train_test_split(review,
                                                    sentiment,
                                                    test_size=0.2)

X_train.shape, X_test.shape

X_train

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()
dt.fit(X_train.todense(), Y_train)
score = dt.score(X_test.todense(), Y_test)
print('Score: %.3f' % score)

Y_pred = dt.predict(X_test.todense())

from sklearn.model_selection import KFold

dtkf = DecisionTreeClassifier()
kf = KFold(n_splits=10)
for train_index, test_index in kf.split(review):
    print("TRAIN:", train_index.shape, "TEST:", test_index.shape)
    X_train, X_test = review[train_index], review[test_index]
    y_train, y_test = sentiment[train_index], sentiment[test_index]
    dtkf.fit(X_train, y_train)
    score = dtkf.score(X_test, y_test)

from sklearn.model_selection import StratifiedKFold

dtkf = DecisionTreeClassifier()
kf = StratifiedKFold(n_splits=10)
for train_index, test_index in kf.split(review, sentiment):
    print("TRAIN:", train_index.shape, "TEST:", test_index.shape)
    X_train, X_test = review[train_index], review[test_index]
    y_train, y_test = sentiment[train_index], sentiment[test_index]
    dtkf.fit(X_train, y_train)
    score = dtkf.score(X_test, y_test)
    print("SCORE:", score)



from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

clf = RandomForestClassifier()
scores = cross_val_score(clf, review, sentiment, cv=5)

scores

! pip  install surprise

from surprise import SVD
from surprise import Dataset
from surprise.model_selection import cross_validate

# Load the movielens-100k dataset (download it if needed).
data = Dataset.load_builtin('ml-100k')

# Use the famous SVD algorithm.
algo = SVD()

# Run 5-fold cross-validation and print results.
cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)



from sklearn.metrics import confusion_matrix
confusion_matrix(Y_test, Y_pred)

from sklearn.metrics import confusion_matrix
tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()
(tn, fp, fn, tp)

from sklearn.metrics import roc_curve
fpr, tpr, _ = roc_curve(y, scores, pos_label=2)

plt.plot(fpr[2], tpr[2], color='darkorange',
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])

