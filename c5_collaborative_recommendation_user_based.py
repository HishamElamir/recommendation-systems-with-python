# -*- coding: utf-8 -*-
"""c5:collaborative_recommendation:user_based.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EB0v9yzJi1cYtbXYtgLHVyJ0CFPDS0Y6
"""



"""## IMPORTING PACKAGES"""

import numpy as np
import pandas as pd

"""## DATA SAMPLE OF MOVIE RATINGS"""

sample_rank_data = [
  {"critic": "Jack Matthews", "title": "Lady in the Water", "rating": 3.0},
  {"critic": "Jack Matthews", "title": "Snakes on a Plane", "rating": 4.0},
  {"critic": "Jack Matthews", "title": "You Me and Dupree", "rating": 3.5},
  {"critic": "Jack Matthews", "title": "Superman Returns", "rating": 5.0},
  {"critic": "Jack Matthews", "title": "The Night Listener", "rating": 3.0},
  {"critic": "Mick LaSalle", "title": "Lady in the Water", "rating": 3.0},
  {"critic": "Mick LaSalle", "title": "Snakes on a Plane", "rating": 4.0},
  {"critic": "Mick LaSalle", "title": "Just My Luck", "rating": 2.0},
  {"critic": "Mick LaSalle", "title": "Superman Returns", "rating": 3.0},
  {"critic": "Mick LaSalle", "title": "You Me and Dupree", "rating": 2.0},
  {"critic": "Mick LaSalle", "title": "The Night Listener", "rating": 3.0},
  {"critic": "Claudia Puig", "title": "Snakes on a Plane", "rating": 3.5},
  {"critic": "Claudia Puig", "title": "Just My Luck", "rating": 3.0},
  {"critic": "Claudia Puig", "title": "You Me and Dupree", "rating": 2.5},
  {"critic": "Claudia Puig", "title": "Superman Returns", "rating": 4.0},
  {"critic": "Claudia Puig", "title": "The Night Listener", "rating": 4.5},
  {"critic": "Lisa Rose", "title": "Lady in the Water", "rating": 2.5},
  {"critic": "Lisa Rose", "title": "Snakes on a Plane", "rating": 3.5},
  {"critic": "Lisa Rose", "title": "Just My Luck", "rating": 3.0},
  {"critic": "Lisa Rose", "title": "Superman Returns", "rating": 3.5},
  {"critic": "Lisa Rose", "title": "The Night Listener", "rating": 3.0},
  {"critic": "Lisa Rose", "title": "You Me and Dupree", "rating": 2.5},
  {"critic": "Toby", "title": "Snakes on a Plane", "rating": 4.5},
  {"critic": "Toby", "title": "Superman Returns", "rating": 4.0},
  {"critic": "Toby", "title": "You Me and Dupree", "rating": 1.0},
  {"critic": "Gene Seymour", "title": "Lady in the Water", "rating": 3.0},
  {"critic": "Gene Seymour", "title": "Snakes on a Plane", "rating": 3.5},
  {"critic": "Gene Seymour", "title": "Just My Luck", "rating": 1.5},
  {"critic": "Gene Seymour", "title": "Superman Returns", "rating": 5.0},
  {"critic": "Gene Seymour", "title": "The Night Listener", "rating": 3.0},
  {"critic": "Gene Seymour", "title": "You Me and Dupree", "rating": 3.5}
]

"""## LOADING AND PROCESSING DATA"""

rating_df = pd.DataFrame(sample_rank_data)

rating_df.head()

"""## CREATING PIVOT MATRIX FOR USER-BASED"""

pivot_table = pd.pivot_table(rating_df, index='title',
                            columns='critic', aggfunc=np.mean)

pivot_table = pivot_table.fillna(0)

pivot_table

pivot_table.corr(method='pearson')

# CORRELATED USERS TO LISA ROSE
pivot_table.corr(method='pearson').iloc[3]

from sklearn.neighbors import NearestNeighbors
model_knn = NearestNeighbors(metric='cosine')

model_knn.fit(pivot_table.T)

pivot_table.T

model_knn.kneighbors([pivot_table.T.iloc[3]], 4, return_distance=True)

"""## CREATING PIVOT MATRIX FOR ITEM-BASED"""

pivot_table = pd.pivot_table(rating_df, index='critic',
                            columns='title', aggfunc=np.mean)

pivot_table

pivot_table = pivot_table.fillna(0)

pivot_table.corr()

# CORRELATED ITEMS TO THE NIGHT LISTENER
pivot_table.corr().iloc[4]

# IMPLEMENT PEARSON SIMILARTITY
# IMPLEMENT CONSINE SIMILARTITY
# IMPLEMENT ENHANCED-CONSINE SIMILARTITY

# doing above on the movielens data

! wget http://files.grouplens.org/datasets/movielens/ml-1m.zip
! unzip ml-1m.zip

import pandas as pd
import numpy as np

from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import pairwise_distances

ratings_df = pd.read_csv('ml-1m/ratings.dat', sep='::',
                        names=['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype=int, engine='python')

movies_df = pd.read_csv('ml-1m/movies.dat', sep='::', names=['MovieID', 'Title', 'Genres'], engine='python')
movies_df['MovieID'] = movies_df['MovieID'].apply(pd.to_numeric)

# one solution
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import scale


def predict(l):
    # finds the userIds corresponding to the top 5 similarities
    # calculate the prediction according to the formula
    return (df[l.index] * l).sum(axis=1) / l.sum()


# use userID as columns for convinience when interpretering the forumla
df = ratings_df.pivot(columns='UserID',
                      index='MovieID',
                      values='Rating')

similarity = pd.DataFrame(cosine_similarity(
    scale(df.T.fillna(-1000))),
    index=df.columns,
    columns=df.columns)

res = df.apply(lambda col: ' '.join('{}'.format(mid) for mid in (0 * col).fillna(
    predict(similarity[col.name].nlargest(6).iloc[1:])).nlargest(5).index))

similarity

# solution two

R_df = pd.pivot_table(ratings_df,
                      values='Rating',index='UserID',columns='MovieID')
R_df = R_df.fillna(R_df.apply(lambda row: row.fillna(row.mean()), axis=1))
R_df.head()

b = cosine_similarity(R_df)
np.fill_diagonal(b, 0)

similarity_with_user = pd.DataFrame(b,index=R_df.index)
similarity_with_user.columns=R_df.index
similarity_with_user.head()

def find_n_neighbours(df,n):
    order = np.argsort(df.values, axis=1)[:, :n]
    df = df.apply(lambda x: pd.Series(x.sort_values(ascending=False)
           .iloc[:n].index, 
          index=['top{}'.format(i) for i in range(1, n+1)]), axis=1)
    return df

def get_user_similar_movies( user1, user2 ):
    common_movies = ratings_df[ratings_df.UserID == user1].merge(
        ratings_df[ratings_df.UserID == user2],
        on = "MovieID",
        how = "inner" )
    return common_movies.merge(movies_df, on = 'MovieID')

# user item based
def predicted_score(user,item):
    a = sim_user_30_m[sim_user_30_m.index==user].values
    b = a.squeeze().tolist()
    c = final_movie.loc[:,item]
    d = c[c.index.isin(b)]
    f = d[d.notnull()]
    avg_user = Mean.loc[Mean['userId'] == user,'rating'].values[0]
    index = f.index.values.squeeze().tolist()
    corr = similarity_with_movie.loc[user,index]
    fin = pd.concat([f, corr], axis=1)
    fin.columns = ['adg_score','correlation']
    fin['score']=fin.apply(lambda x:x['adg_score'] * x['correlation'],axis=1)
    nume = fin['score'].sum()
    deno = fin['correlation'].sum()
    final_score = avg_user + (nume/deno)
    return final_score
# user item
def recommended_movies(user):
    Movie_seen_by_user = check.columns[check[check.index==user].notna().any()].tolist()
    a = sim_user_30_m[sim_user_30_m.index==user].values
    b = a.squeeze().tolist()
    d = Movie_user[Movie_user.index.isin(b)]
    l = ','.join(d.values)
    Movie_seen_by_similar_users = l.split(',')
    Movies_under_consideration = list(set(Movie_seen_by_similar_users)-set(list(map(str, Movie_seen_by_user))))
    Movies_under_consideration = list(map(int, Movies_under_consideration))
    score = []
    for item in Movies_under_consideration:
        c = final_movie.loc[:,item]
        d = c[c.index.isin(b)]
        f = d[d.notnull()]
        avg_user = Mean.loc[Mean['userId'] == user,'rating'].values[0]
        index = f.index.values.squeeze().tolist()
        corr = similarity_with_movie.loc[user,index]
        fin = pd.concat([f, corr], axis=1)
        fin.columns = ['adg_score','correlation']
        fin['score']=fin.apply(lambda x:x['adg_score'] * x['correlation'],axis=1)
        nume = fin['score'].sum()
        deno = fin['correlation'].sum()
        final_score = avg_user + (nume/deno)
        score.append(final_score)
    data = pd.DataFrame({'movieId':Movies_under_consideration,'score':score})
    top_5_recommendation = data.sort_values(by='score',ascending=False).head(5)
    Movie_Name = top_5_recommendation.merge(movies, how='inner', on='movieId')
    Movie_Names = Movie_Name.title.values.tolist()
    return Movie_Names

# top 30 neighbours for each user
sim_user_30_u = find_n_neighbours(similarity_with_user,30)
sim_user_30_u

a = get_user_similar_movies(1,283)
a = a.loc[ : ]
a.head()

sim_user = find_n_neighbours(similarity_with_user, 5)
sim_user = pd.DataFrame(sim_user.iloc[1].values, columns=['UserID'])
sim_user

sim_user.apply(lambda x: print(x.values))



# get movies u1 did not not
def s_users(u, num_recommendations=5):
  user_data = ratings_df[ratings_df.UserID == (u)]
  user_full = (user_data.merge(movies_df, how = 'left', left_on = 'MovieID', right_on = 'MovieID')\
               .sort_values(['Rating'], ascending=False))
  print('User {0} has already rated {1} movies.'.format(u, user_full.shape[0]))
  print('Recommending the highest {0} predicted ratings movies not already rated.'.format(num_recommendations))

  recommendations = (movies_df[~movies_df['MovieID'].isin(user_full['MovieID'])].
         merge(pd.DataFrame(sorted_user_predictions).reset_index(), how = 'left',
               left_on = 'MovieID',
               right_on = 'MovieID').
         rename(columns = {user_row_number: 'Predictions'}).
         sort_values('Predictions', ascending = False).
                       iloc[:num_recommendations, :-1])

  return user_full

s_users(1)

